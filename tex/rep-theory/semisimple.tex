\chapter{Semisimple algebras}
In what follows, \textbf{assume the field $k$ is algebraically closed}.

Fix an algebra $A$ and suppose
you want to study its representations.
We have a ``direct sum'' operation already.
So, much like we pay special attention to prime numbers,
we're motivated to study irreducible representations
and then build all the representations of $A$ from there.

Unfortunately, we have seen (\Cref{exer:irred_not_indecomp})
that there exists a representation which is not irreducible,
and yet cannot be broken down as a direct sum (indecomposable).
This is \emph{weird and bad}, so we want to give a name
to representations which are more well-behaved.
We say that a representation is \vocab{completely reducible}
if it doesn't exhibit this bad behavior.

Even better, we say a finite-dimensional algebra $A$
is \vocab{semisimple} if all its finite-dimensional
representations are completely reducible.
So when we study finite-dimensional representations of
semisimple algebras $A$,
we just have to figure out what the irreps are,
and then piecing them together will give all
the representations of $A$.

In fact, semisimple algebras $A$ have even nicer properties.
The culminating point of the chapter is when we prove that
$A$ is semisimple if and only if $A \cong \bigoplus_i \Mat(V_i)$,
where the $V_i$ are the irreps of $A$
(yes, there are only finitely many!).

In the end, we will see that the group algebras $k[G]$ of a finite group $G$ are
all semisimple (at least when $k$ has characteristic $0$), thus we're justified in
focusing on studying the semisimple algebras.

\begin{remark}
	[Digression]
	The converse does not hold, however --- if $k$ has characteristic $0$, not
	every finite-dimensional semisimple $k$-algebra is isomorphic to some group algebra.
	Classifying exactly when a $k$-algebra is isomorphic to a group algebra
	turns out to be a hard question, see \url{https://mathoverflow.net/q/314502}.
\end{remark}

\section{Schur's lemma continued}
\prototype{For $V$ irreducible,
	$\Homrep(V^{\oplus 2}, V^{\oplus 2}) \cong k^{\oplus 4}$.}
\begin{definition}
	For an algebra $A$ and representations $V$ and $W$,
	we let $\Homrep(V,W)$ be the set of intertwining operators between them.
	(It is also a $k$-algebra.)
\end{definition}

By Schur's lemma (since $k$ is algebraically closed,
which again, we are taking as a standing assumption),
we already know that if $V$ and $W$ are irreps, then
\[
	\Homrep(V,W) \cong
	\begin{cases}
		k & \text{if $V \cong W$} \\
		0 & \text{if $V \not\cong W$}.
	\end{cases}
\]
Can we say anything more?
For example, it also tells us that
\[ \Homrep(V, V^{\oplus 2}) = k^{\oplus 2}. \]
The possible maps are $v \mapsto (c_1v_1, c_2v_2)$ for some choice of $c_1, c_2 \in k$.

More generally, suppose $V$ is an irrep and consider
$\Homrep(V^{\oplus m}, V^{\oplus n})$.
Intertwining operators
$T \colon V^{\oplus m} \to V^{\oplus n}$
are determined completely
by the $mn$ choices of compositions
\begin{center}
\begin{tikzcd}
	V \ar[r, hook] & V^{\oplus m} \ar[r, "T"] & V^{\oplus n} \ar[r, surjective head] & V
\end{tikzcd}
\end{center}
where the first arrow is inclusion to the $i$th component of $V^{\oplus m}$
(for $1 \le i \le m$) and the second arrow is inclusion to the $j$th
component of $V^{\oplus n}$ (for $1 \le j \le n$).
However, by Schur's lemma on each of these compositions,
we know they must be constant.

Thus, $\Homrep(V^{\oplus n}, V^{\oplus m})$ consist of $n \times m$ ``matrices''
of constants, and the map is provided by
\[
	\begin{bmatrix}
		c_{11} & c_{12} & \dots & c_{1(n-1)} & c_{1n} \\
		c_{21} & c_{22} & \dots & c_{2(n-1)} & c_{2n} \\
		\vdots & \vdots & \ddots & \vdots & \vdots \\
		c_{m1} & c_{m2} & \dots & c_{m(n-1)} & c_{mn}
	\end{bmatrix}
	\begin{bmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{bmatrix}
	\in V^{\oplus m}
\]
where the $c_{ij} \in k$ but $v_i \in V$; note the type mismatch!
This is \emph{not} just a $k$-linear map $V^{\oplus n} \to V^{\oplus m}$;
rather, the outputs are $m$ \emph{linear combinations} of the inputs.

More generally, we have:
\begin{theorem}
	[Schur's lemma for completely reducible representations]
	\label{thm:compred_schur}
	Let $V$ and $W$ be completely reducible representations,
	and set $V = \bigoplus V_i^{\oplus n_i}$, $W = \bigoplus V_i^{\oplus m_i}$
	for integers $n_i, m_i \ge 0$, where each $V_i$ is an irrep.
	Then
	\[ \Homrep(V, W)
		\cong \bigoplus_i \Mat_{m_i \times n_i}(k) \]
	meaning that an intertwining operator $T \colon V \to W$
	amounts to, for each $i$, an $m_i \times n_i$ matrix of constants
	which gives a map $V_i^{\oplus n_i} \to V_i^{\oplus m_i}$.
\end{theorem}

\begin{corollary}
	[Subrepresentations of completely reducible representations]
	\label{cor:subrep_schur}
	Let $V = \bigoplus V_i^{\oplus n_i}$ be completely reducible.
	Then any subrepresentation $W$ of $V$ is isomorphic
	to $\bigoplus V_i^{\oplus m_i}$ where $m_i \le n_i$ for each $i$,
	and the inclusion $W \injto V$ is given
	by the direct sum of inclusion $V_i^{\oplus m_i} \injto V_i^{\oplus n_i}$,
	which are $n_i \times m_i$ matrices.
\end{corollary}
\begin{proof}
	Apply Schur's lemma to the inclusion $W \injto V$.
\end{proof}
Recall from \Cref{sec:vector_space_linear_maps} that a linear maps from a
$n$-dimensional vector space to a $m$-dimensional vector space can be written as
a $n \times m$ matrix. Here the situation is similar, however the matrices are
made for each irrep independently, and the non-isomorphic irreps, in some sense,
``doesn't talk to each other''.

%We can compare this to \label{prop:rep_direct_sum}: When our $k$-algebra is a
%direct sum $A \oplus B$, then every representation $V$ can be broken down
%cleanly into $V_A \oplus V_B$, and there is no ``mixing'' between the action of
%$A$ and $B$ on $V_A$ and $V_B$.

\begin{remark}
	The representation $V^{\oplus n}$ can also be viewed as $n$
	vectors of $V$ ``stacked horizontally'', as we did in
	\Cref{ex:mat2_representation}:
	\[
		\begin{pmatrix}
			\vdots & \vdots & & \vdots \\
			v_1 & v_2 & \cdots & v_n \\
			\vdots & \vdots & & \vdots
		\end{pmatrix} \in V^{\oplus n}.
	\]
	That way, the action is given by
	\[
		\begin{pmatrix}
			\vdots & \vdots & & \vdots \\
			v_1 & v_2 & \cdots & v_n \\
			\vdots & \vdots & & \vdots
		\end{pmatrix}
		\begin{bmatrix}
			c_{11} & c_{21} & \cdots & c_{(m-1)1} & c_{m1} \\
			c_{12} & c_{22} & \cdots & c_{(m-1)1} & c_{m2} \\
			\vdots & \vdots & \ddots & \vdots & \vdots \\
			c_{1n} & c_{2n} & \cdots & c_{(m-1)n} & c_{mn}
		\end{bmatrix}
		\in V^{\oplus m}.
	\]
	It may be clearer this way to see the type mismatch happening.
	And this also gives a natural explanation why the intertwining operators in
	\Cref{prob:regA_intertwine} corresponds to right matrix multiplication.
\end{remark}

\section{Density theorem}
We are going to take advantage of the previous result to prove that
finite-dimensional algebras have finitely many irreps.

\begin{theorem}
	[Jacobson density theorem]
	Let $(V_1, \rho_1)$, \dots, $(V_r, \rho_r)$ be pairwise nonisomorphic
	irreps of $A$.
	Then there is a surjective map of vector spaces
	\[ \bigoplus_{i=1}^r \rho_i \colon A \surjto \bigoplus_{i=1}^r \Mat(V_i). \]
\end{theorem}
The right way to think about this theorem is that
\begin{moral}
	Density is the ``Chinese remainder theorem''
	for irreps of $A$.
\end{moral}
Recall that in number theory, the Chinese remainder theorem tells us
that given lots of ``unrelated'' congruences, we can find a single $N$
which simultaneously satisfies them all.
Similarly, given lots of different nonisomorphic irreps of $A$,
this means that we can select a single $a \in A$ which induces any tuple
$(\rho_1(a), \dots, \rho_r(a))$ of actions we want --- a surprising result,
since even the $r=1$ case is not obvious at all!
\begin{center}
	\begin{tikzcd}[column sep=huge, row sep= tiny]
		& \rho_1(a) = M_1 \in \Mat(V_1) \\
		& \rho_2(a) = M_2 \in \Mat(V_2) \\
		\boxed{a \in A} \ar[ruu, end anchor=west] \ar[ru, end anchor=west] \ar[rd, end anchor=west] & \vdots \\
		& \rho_r(a) = M_r \in \Mat(V_r) \\
	\end{tikzcd}
\end{center}
This also gives us the non-obvious corollary:
\begin{corollary}
	[Finiteness of number of representations]
	Any finite-dimensional algebra $A$ has at most $\dim A$ irreps.
	\label{cor:finiteness}
\end{corollary}
\begin{proof}
	If $V_i$ are such irreps then
	$A \surjto \bigoplus_i V_i^{\oplus \dim V_i}$,
	hence we have the inequality $\sum (\dim V_i)^2 \le \dim A$.
\end{proof}

\begin{proof}[Proof of density theorem]
	Let $V = V_1 \oplus \dots \oplus V_r$, so $A$
	acts on $V = (V, \rho)$ by $\rho = \bigoplus_i \rho_i$.
	Thus by \Cref{prob:reg_mat}, we can instead consider $\rho$
	as an \emph{intertwining operator}
	\[ \rho \colon \Reg(A) \to \bigoplus_{i=1}^r \Mat(V_i)
		\cong \bigoplus_{i=1}^r V_i^{\oplus d_i}. \]
	We will use this instead as it will be easier to work with.

	First, we handle the case $r = 1$.
	Fix a basis $e_1$, \dots, $e_n$ of $V = V_1$.
	Assume for contradiction that the map is not surjective.
	Then there is a map of representations (by $\rho$ and the isomorphism)
	$\Reg(A) \to V^{\oplus n}$ given by $a \mapsto (a \cdot e_1, \dots, a \cdot e_n)$.
	By hypothesis, it is not surjective:
	its image is a \emph{proper} subrepresentation of $V^{\oplus n}$.
	Assume its image is isomorphic to $V^{\oplus m}$ for $m < n$,
	so by \Cref{thm:compred_schur} there is a matrix of constants $X$ with
	\begin{center}
		\begin{tikzcd}[row sep=tiny]
			\Reg(A) \ar[r] & V^{\oplus n} & \ar[l, "X \cdot -", hook'] V^{\oplus m} \\
			a \ar[r, mapsto] & (a \cdot e_1, \dots, a \cdot e_n) \\
			1_A \ar[r, mapsto] & (e_1, \dots, e_n) & \ar[l, mapsto] (v_1, \dots, v_m)
		\end{tikzcd}
	\end{center}
	where the two arrows in the top row have the same image;
	hence the pre-image $(v_1, \dots, v_m)$ of $(e_1, \dots, e_n)$ can be found.
	But since $m < n$ we can find constants $c_1, \dots, c_n$ not all zero
	such that $X$ applied to the column vector $(c_1, \dots, c_n)$ is zero:
	\[
		\sum_{i=1}^n c_ie_i
		=
		\begin{bmatrix} c_1 & \dots & c_n \end{bmatrix}
		\begin{bmatrix} e_1 \\ \vdots \\ e_n \end{bmatrix}
		=
		\begin{bmatrix} c_1 & \dots & c_n \end{bmatrix}
		X
		\begin{bmatrix} v_1 \\ \vdots \\ v_m \end{bmatrix}
		= 0
	\]
	contradicting the fact that $e_i$ are linearly independent.
	Hence we conclude the theorem for $r=1$.

	As for $r \ge 2$, the image $\rho\im(A)$ is necessarily of the form
	$\bigoplus_i V_i^{\oplus d_i}$ (by \Cref{cor:subrep_schur})
	and by the above $d_i = \dim V_i$ for each $i$.
\end{proof}
% there's another proof in https://www3.nd.edu/~andyp/notes/JacobsonDensity.pdf
% which might be more digestible

\begin{example}
	[Applying the proof of density theorem on an explicit example]
	We can run through the argument on an explicit example to better understand
	how it works --- in order to do this, we need $V$ to be an irrep,
	otherwise the image of $\Reg(A)$ would not be isomorphic to $V^{\oplus m}$,
	and we will not be able to run to the end of the argument.

	Let $A=\Mat_2(k)$, and $V \cong k^{\oplus 2}$ with the obvious action.
	As we know, this is an irrep.

	The density theorem claims that $\rho \colon A \to \Mat(V)$ is surjective, which
	means for any $e_1, e_2 \in V$ independent, and any $w_1, w_2 \in V$, we can
	find $a \in A$ such that $a \cdot (e_1, e_2) = (w_1, w_2)$.

	Because we're working through a counterexample, pick $e_1=(1, 0)$, $e_2=(2, 0)$ instead.
	Then, for some $w_1, w_2 \in V$,
	there may be no $a$ that sends $e_1$ to $w_1$ to $e_2$ to $w_2$.

	Consider the representation morphism $\Reg(A) \to V^{\oplus 2}$ by
	$a \mapsto(a \cdot e_1, a \cdot e_2)$;
	its image is thus $\{(v, 2v) \mid v \in V \}$,
	which is a subrepresentation of $V^{\oplus 2}$,
	isomorphic as a representation to $V^{\oplus 1}\cong V$ by
	\[ v \mapsto(v, 2v) = v \begin{bmatrix} 1 & 2 \end{bmatrix}. \]
	Then, we can find $v=\begin{pmatrix}1 \\ 0\end{pmatrix}\in V^{\oplus 1}$,
	for which
	\[ \begin{pmatrix} e_1 & e_2 \end{pmatrix} = v \begin{bmatrix} 1 & 2 \end{bmatrix}. \]
	Now, with the explicit array of numbers $\begin{bmatrix} 1 & 2 \end{bmatrix}$,
	it is easy to find a linear dependence on $e_1$ and $e_2$.
\end{example}

\section{Semisimple algebras}
\begin{definition}
	A finite-dimensional algebra $A$ is a \vocab{semisimple}
	if every finite-dimensional representation of $A$ is completely reducible.
\end{definition}

\begin{theorem}
	[Semisimple algebras]
	Let $A$ be a finite-dimensional algebra.
	Then the following are equivalent:
	\begin{enumerate}[(i)]
		\ii $A \cong \bigoplus_i \Mat_{d_i}(k)$ for some $d_i$.
		\ii $A$ is semisimple.
		\ii $\Reg(A)$ is completely reducible.
	\end{enumerate}
\end{theorem}
\begin{proof}
	(i) $\implies$ (ii) follows from
	using \Cref{prop:rep_direct_sum} to breaks any finite-dimensional
	representation of $A$ into a direct sum of representations of
	$\Mat_{d_i}(k)$, then \Cref{thm:rep_1mat} shows any such representations are
	completely reducible.
	(ii) $\implies$ (iii) is tautological.

	To see (iii) $\implies$ (i), we use the following clever trick.
	Consider
	\[ \Homrep(\Reg(A), \Reg(A)). \]
	On one hand, by \Cref{prob:regA_intertwine},
	it is isomorphic to $A\op$ ($A$ with opposite multiplication),
	because the only intertwining operators $\Reg(A) \to \Reg(A)$
	are those of the form $- \cdot a$.
	On the other hand, suppose that we have set
	$ \Reg(A) = \bigoplus_i V_i^{\oplus n_i} $.
	By \Cref{thm:compred_schur}, we have
	\[ A\op \cong \Homrep(\Reg(A), \Reg(A))
		= \bigoplus_i \Mat_{n_i \times n_i}(k). \]
	But $\Mat_n(k)\op \cong \Mat_n(k)$ (just by transposing),
	so we recover the desired conclusion.
\end{proof}

\begin{remark}
	The trick of the proof above resembles
	Cayley's theorem (\Cref{thm:cayley_theorem}), in that we make the object
	act on itself to get an explicit representation.
\end{remark}

\begin{remark}
	We can compare this to \Cref{cor:structure_theorem_primary}.
	Here, any finite-dimensional representation of $A$ is a
	finite-dimensional left $A$-module, and from the theorem above,
	we know that if $A$ is semisimple, any such module
	can be broken down into a direct sum of irreps $V_i \cong k^{\oplus d_i}$.

	Note that unlike the case where $A$ is a PID,
	$k^{\oplus d_i}$ is not isomorphic to a quotient of the ring $\Mat_{d_i}(k)$.
\end{remark}

In fact, if we combine the above result with
the density theorem (and \Cref{cor:finiteness}), we obtain:
\begin{theorem}
	[Sum of squares formula]
	For a finite-dimensional algebra $A$ we have
	\[ \sum_{i} \dim(V_i)^2 \le \dim A \]
	where the $V_i$ are the irreps of $A$;
	equality holds exactly when $A$ is semisimple,
	in which case
	\[ \Reg(A) \cong \bigoplus_i \Mat(V_i)
		\cong \bigoplus_I V_i^{\oplus \dim V_i}. \]
\end{theorem}
\begin{proof}
	The inequality was already mentioned in \Cref{cor:finiteness}.
	It is equality if and only if the map $\rho \colon A \to \bigoplus_i \Mat(V_i)$
	is an isomorphism; this means all $V_i$ are present.
\end{proof}

\begin{remark}
	[Digression]
	For any finite-dimensional $A$, the kernel of the map
	$\rho \colon A \to \bigoplus_i \Mat(V_i)$ is denoted $\opname{Rad}(A)$
	and is the so-called \vocab{Jacobson radical} of $A$;
	it's the set of all $a \in A$ which act by zero in all irreps of $A$.
	The usual definition of ``semisimple'' given in books is that
	this Jacobson radical is trivial.
\end{remark}

\section{Maschke's theorem}
We now prove that the representation theory of groups is as nice as possible.
\begin{theorem}
	[Maschke's theorem]
	Let $G$ be a finite group, and $k$ an algebraically closed
	field whose characteristic does not divide $|G|$.
	Then $k[G]$ is semisimple.
\end{theorem}
This tells us that when studying representations of groups,
all representations are completely reducible.
\begin{proof}
	Consider any finite-dimensional representation $(V, \rho)$ of $k[G]$.
	Given a proper subrepresentation $W \subseteq V$,
	our goal is to construct a supplementary $G$-invariant subspace $W'$
	which satisfies \[ V = W \oplus W'. \]
	This will show that indecomposable $\iff$ irreducible,
	which is enough to show $k[G]$ is semisimple.

	Let $\pi \colon V \to W$ be any projection of $V$ onto $W$,
	meaning $\pi(v) = v \iff v \in W$.
	We consider the \emph{averaging} map $P \colon V \to V$ by
	\[
		P = \frac{1}{\left\lvert G \right\rvert}
		\sum_{g \in G} \rho(g\inv) \circ \pi \circ \rho(g).
	\]
	We'll use the following properties of the map:
	\begin{exercise}
		Show that the map $P$ satisfies:
		\begin{itemize}
			\ii For any $w \in W$, $P(w) = w$.
			\ii For any $v \in V$, $P(v) \in W$.
			\ii The map $P \colon V \to V$ is an intertwining operator.
		\end{itemize}
	\end{exercise}
	Thus $P$ is idempotent (it is the identity on its image $W$),
	so by \Cref{prob:idempotent} we have $V = \ker P \oplus \img P$,
	but both $\ker P$ and $\img P$ are subrepresentations as desired.
\end{proof}
\begin{remark}
	In the case where $k = \CC$, there is a shorter proof.
	Suppose $B \colon V \times V \to \CC$ is an arbitrary bilinear form.
	Then we can ``average'' it to obtain a new bilinear form
	\[ \left< v,w \right> \defeq \frac{1}{|G|} \sum_{g \in G} B(g \cdot v, g \cdot w). \]
	The averaged form $\left< -,- \right>$ is $G$-invariant,
	in the sense that $\left< v,w \right> = \left< g \cdot v, g \cdot w\right>$.
	Then, one sees that if $W \subseteq V$ is a subrepresentation,
	so is its orthogonal complement $W^\perp$.
	This implies the result.
\end{remark}

\section{Example: the representations of $\CC[S_3]$}
We compute all irreps of $\CC[S_3]$.
I'll take for granted right now there are exactly three such representations
(which will be immediate by the first theorem in the next chapter:
we'll in fact see that the number of representations of $G$
is exactly equal to the number of conjugacy classes of $G$).

Given that, if the three representations of have dimension $d_1$, $d_2$, $d_3$ ,
then we ought to have
\[ d_1^2 + d_2^2 + d_3^2 = |G| = 6. \]
From this, combined with some deep arithmetic,
we deduce that we should have $d_1 = d_2 = 1$ and $d_3 = 2$
or some permutation.

In fact, we can describe these representations explicitly.
First, we define:
\begin{definition}
	Let $G$ be a group.
	The complex \vocab{trivial group representation} of a group $G$
	is the one-dimensional representation $\Ctriv = (\CC, \rho)$
	where $g \cdot v = v$ for all $g \in G$ and $v \in \CC$
	(i.e.\ $\rho(g) = \id$ for all $g \in G$).
\end{definition}
\begin{remark}
	[Warning] The trivial representation of an \emph{algebra} $A$
	doesn't make sense for us:
	we might want to set $a \cdot v = v$ but this isn't linear in $A$.
	(You \emph{could} try to force it to work by
	deleting the condition $1_A \cdot v = v$ from our definition;
	then one can just set $a \cdot v = 0$.
	But even then $\Ctriv$ would not be the trivial representation of $k[G]$.)

	Another way to see this is that the trivial representation
	depends on how the $k$-algebra is written as a group algebra:
	$k[\ZZ/2\ZZ]$ has a $k$-algebra automorphism given by $g \mapsto-g$, where
	$g$ is the generator of the group $\ZZ/2\ZZ$; however the corresponding
	trivial representations are different.
\end{remark}

Then the representations are:
\begin{itemize}
	\ii The one-dimensional $\Ctriv$;
	each $\sigma \in S_3$ acts by the identity.

	\ii There is a nontrivial one-dimensional representation
	$\Csign$ where the map $S_3 \to \CC^\times$ is given
	by sending $\sigma$ to the sign of $\sigma$.
	Thus in $\Csign$ every $\sigma \in S_3$ acts as $\pm 1$.
	Of course, $\Ctriv$ and $\Csign$ are not isomorphic
	(as one-dimensional representations are never isomorphic
	unless the constants they act on coincide for all $a$,
	as we saw in \Cref{prob:one_dim}).

	\ii Finally, we have already seen the two-dimensional representation,
	but now we give it a name.
	Define $\refl_0$ to be the representation whose vector space is
	$\{ (x,y,z) \mid x+y+z = 0 \}$,
	and whose action of $S_3$ on it is permutation of coordinates.
	\begin{exercise}
		Show that $\refl_0$ is irreducible, for example by showing directly
		that no subspace is invariant under the action of $S_3$.
	\end{exercise}
	Thus $V$ is also not isomorphic to the previous two representations.
\end{itemize}
This implies that these are all the irreps of $S_3$.
Note that, if we take the representation $V$ of $S_3$ on $k^{\oplus 3}$,
we just get that $V = \refl_0 \oplus \CC_{\text{triv}}$.

\section\problemhead

\begin{problem}
	Find all the irreps of $\CC[\Zc n]$.
	\begin{hint}
		They are all one-dimensional, $n$ of them.
		What are the homomorphisms $\Zc n \to \CC^\times$?
	\end{hint}
\end{problem}

\begin{problem}
	[Maschke requires $|G|$ finite]
	Consider the representation of the group $\RR$
	on $\CC^{\oplus 2}$ under addition by a homomorphism
	\[
		\RR \to \Mat_2(\CC)
		\quad\text{by}\quad
		t \mapsto
		\begin{bmatrix} 1 & t \\ 0 & 1 \end{bmatrix}.
	\]
	Show that this representation is not irreducible,
	but it is indecomposable.
	\begin{hint}
		The span of $(1,0)$ is a subrepresentation.
	\end{hint}
\end{problem}

\begin{problem}
	Prove that all irreducible representations
	of a finite group are finite-dimensional.
	\begin{hint}
		This is actually easy.
	\end{hint}
	\begin{sol}
		Pick any $v \in V$, then the subspace
		spanned by elements $g \cdot v$ for $v \in V$
		is $G$-invariant;
		this is a finite-dimensional subspace,
		so it must equal all of $V$.
	\end{sol}
\end{problem}

\begin{problem}
	\label{prob:dten_irrep}
	Determine all the complex irreps of $D_{10}$.
	\begin{hint}
		There are only two one-dimensional ones
		(corresponding to the only two homomorphisms $D_{10} \to \CC^\times$).
		So the remaining ones are two-dimensional.
	\end{hint}
\end{problem}

\begin{problem}
	[AIME 2018]
	\gim
	The wheel shown below consists of two circles and five spokes, with a label
	where a spoke meets a circle. A bug walks along the wheel, starting from $A$.
	The bug takes $15$ steps. At each step, the bug moves to an adjacent label such
	that it only walks counterclockwise along the inner circle and clockwise along the
	outer circle. In how many ways can the bug move to end up at $A$ after all steps?
	\begin{center}
		\begin{asy}
		size(5cm);
		draw(unitcircle);
		draw(scale(2) * unitcircle);
		for (int d = 90; d < 360 + 90; d += 72) {
			draw(2*dir(d) --dir(d));
			dot(dir(d));
			dot(2*dir(d));
		}
		label("$A$", 0.95*dir(90), -dir(90));
		\end{asy}
	\end{center}
	\begin{hint}
		Let $r, t \in D_{10}$ be rotation and reflection respectively. Then we can sum over all possible bug's moves with
		\[ \frac{1}{10} \Tr (\rho(r) + \rho(t))^{15}. \]
		Then use \Cref{prob:dten_irrep} to compute this trace.
	\end{hint}
\end{problem}
